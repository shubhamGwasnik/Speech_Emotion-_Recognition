{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries \nimport librosa\nimport librosa.display\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom matplotlib.pyplot import specgram\nimport pandas as pd\nimport glob \nfrom sklearn.metrics import confusion_matrix\nimport IPython.display as ipd  # To play sound in the notebook\nimport os\nimport sys\nimport warnings\n# ignore warnings \nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-01T20:05:02.730418Z","iopub.execute_input":"2022-05-01T20:05:02.730749Z","iopub.status.idle":"2022-05-01T20:05:02.737832Z","shell.execute_reply.started":"2022-05-01T20:05:02.730674Z","shell.execute_reply":"2022-05-01T20:05:02.736886Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\nTESS = \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\nRAV = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:02.875465Z","iopub.execute_input":"2022-05-01T20:05:02.875880Z","iopub.status.idle":"2022-05-01T20:05:02.880336Z","shell.execute_reply.started":"2022-05-01T20:05:02.875691Z","shell.execute_reply":"2022-05-01T20:05:02.879454Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"dir_list = os.listdir(RAV)\ndir_list.sort()\n\nemotion = []\ngender = []\npath = []\nfor i in dir_list:\n    fname = os.listdir(RAV + i)\n    for f in fname:\n        part = f.split('.')[0].split('-')\n        emotion.append(int(part[2]))\n        temp = int(part[6])\n        if temp%2 == 0:\n            temp = \"female\"\n        else:\n            temp = \"male\"\n        gender.append(temp)\n        path.append(RAV + i + '/' + f)\n\n        \nRAV_df = pd.DataFrame(emotion)\nRAV_df = RAV_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\nRAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\nRAV_df.columns = ['gender','emotion']\nRAV_df['labels'] =RAV_df.gender + '_' + RAV_df.emotion\nRAV_df['source'] = 'RAVDESS'  \nRAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)\nRAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\nRAV_df.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:02.954192Z","iopub.execute_input":"2022-05-01T20:05:02.954470Z","iopub.status.idle":"2022-05-01T20:05:03.004482Z","shell.execute_reply.started":"2022-05-01T20:05:02.954422Z","shell.execute_reply":"2022-05-01T20:05:03.003823Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"# Pick a fearful track\nfname = RAV + 'Actor_14/03-01-06-02-02-02-14.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:03.065345Z","iopub.execute_input":"2022-05-01T20:05:03.065573Z","iopub.status.idle":"2022-05-01T20:05:03.408378Z","shell.execute_reply.started":"2022-05-01T20:05:03.065530Z","shell.execute_reply":"2022-05-01T20:05:03.407597Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"# Pick a happy track\nfname = RAV + 'Actor_14/03-01-03-02-02-02-14.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:03.410126Z","iopub.execute_input":"2022-05-01T20:05:03.410554Z","iopub.status.idle":"2022-05-01T20:05:03.776185Z","shell.execute_reply.started":"2022-05-01T20:05:03.410503Z","shell.execute_reply":"2022-05-01T20:05:03.774520Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"dir_list = os.listdir(TESS)\ndir_list.sort()\ndir_list","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:03.778772Z","iopub.execute_input":"2022-05-01T20:05:03.779261Z","iopub.status.idle":"2022-05-01T20:05:03.788482Z","shell.execute_reply.started":"2022-05-01T20:05:03.779210Z","shell.execute_reply":"2022-05-01T20:05:03.786997Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"path = []\nemotion = []\n\nfor i in dir_list:\n    fname = os.listdir(TESS + i)\n    for f in fname:\n        if i == 'OAF_angry' or i == 'YAF_angry':\n            emotion.append('female_angry')\n        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n            emotion.append('female_disgust')\n        elif i == 'OAF_Fear' or i == 'YAF_fear':\n            emotion.append('female_fear')\n        elif i == 'OAF_happy' or i == 'YAF_happy':\n            emotion.append('female_happy')\n        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n            emotion.append('female_neutral')                                \n        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n            emotion.append('female_surprise')               \n        elif i == 'OAF_Sad' or i == 'YAF_sad':\n            emotion.append('female_sad')\n        else:\n            emotion.append('Unknown')\n        path.append(TESS + i + \"/\" + f)\n\nTESS_df = pd.DataFrame(emotion, columns = ['labels'])\nTESS_df['source'] = 'TESS'\nTESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\nTESS_df.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:03.790286Z","iopub.execute_input":"2022-05-01T20:05:03.790593Z","iopub.status.idle":"2022-05-01T20:05:03.828281Z","shell.execute_reply.started":"2022-05-01T20:05:03.790540Z","shell.execute_reply":"2022-05-01T20:05:03.827680Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"# lets play a fearful track \nfname = TESS + 'YAF_fear/YAF_dog_fear.wav' \n\ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:03.830513Z","iopub.execute_input":"2022-05-01T20:05:03.830799Z","iopub.status.idle":"2022-05-01T20:05:04.402559Z","shell.execute_reply.started":"2022-05-01T20:05:03.830755Z","shell.execute_reply":"2022-05-01T20:05:04.401695Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# lets play a happy track \nfname =  TESS + 'YAF_happy/YAF_dog_happy.wav' \n\ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:04.404627Z","iopub.execute_input":"2022-05-01T20:05:04.406888Z","iopub.status.idle":"2022-05-01T20:05:05.173698Z","shell.execute_reply.started":"2022-05-01T20:05:04.406832Z","shell.execute_reply":"2022-05-01T20:05:05.172800Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"EmotionData = pd.concat([ RAV_df, TESS_df], axis = 0)\nprint(EmotionData.labels.value_counts())\n#EmotionData.head()\nEmotionData.to_csv(\"Data_path.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:05.175278Z","iopub.execute_input":"2022-05-01T20:05:05.175836Z","iopub.status.idle":"2022-05-01T20:05:05.221848Z","shell.execute_reply.started":"2022-05-01T20:05:05.175773Z","shell.execute_reply":"2022-05-01T20:05:05.221073Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"EmotionData.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:05.223128Z","iopub.execute_input":"2022-05-01T20:05:05.223586Z","iopub.status.idle":"2022-05-01T20:05:05.237426Z","shell.execute_reply.started":"2022-05-01T20:05:05.223535Z","shell.execute_reply":"2022-05-01T20:05:05.236801Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# lets pick up the meta-data that we got from our first part of the Kernel\nref = pd.read_csv(\"Data_path.csv\")\nref.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:05.239679Z","iopub.execute_input":"2022-05-01T20:05:05.240167Z","iopub.status.idle":"2022-05-01T20:05:05.264331Z","shell.execute_reply.started":"2022-05-01T20:05:05.240114Z","shell.execute_reply":"2022-05-01T20:05:05.263680Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"**FEATURE EXTRACTION**\nThere are lots of features which we can get from an audio data such as \n* Spectral Centroid\n* Zero Crossing Rate\n* Chroma Frequencies\n* Mel Frequency Ceptral Coefficient(MFCC)\n* Spectral Roll off\nBut for human voice characterization and modelling MFCC is the best feature so that's why we are using MFCC feature and extract it for each of the data.","metadata":{}},{"cell_type":"markdown","source":"Lets extract MFCC feature for one of the example voice","metadata":{}},{"cell_type":"code","source":"# Source - RAVDESS; Gender - Male; Emotion - Happy \npath = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_11/03-01-03-01-02-02-11.wav\"\nX, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)  \nmfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n\n# audio wave\nplt.figure(figsize=(20, 15))\nplt.subplot(3,1,1)\nlibrosa.display.waveplot(X, sr=sample_rate)\nplt.title('Audio sampled at 44100 hrz')\n\n# MFCC\nplt.figure(figsize=(20, 15))\nplt.subplot(3,1,1)\n#Here we are displaying Spectrogram for the Happy voice and lets visualiza how its look like\nlibrosa.display.specshow(mfcc, x_axis='time')\nplt.ylabel('MFCC')\nplt.colorbar()\n\nipd.Audio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:05.265941Z","iopub.execute_input":"2022-05-01T20:05:05.266390Z","iopub.status.idle":"2022-05-01T20:05:05.850631Z","shell.execute_reply.started":"2022-05-01T20:05:05.266189Z","shell.execute_reply":"2022-05-01T20:05:05.849683Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"markdown","source":"Now lets extract this feature for entire dataset and then concatinate this feature column into our dataframe","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(columns=['feature'])\n\n# loop feature extraction over the entire dataset\ncounter=0\nfor index,path in enumerate(ref.path):\n    X, sample_rate = librosa.load(path\n                                  , res_type='kaiser_fast'\n                                  ,duration=2.5\n                                  ,sr=44100\n                                  ,offset=0.5\n                                 )\n    sample_rate = np.array(sample_rate)\n    \n    # mean as the feature. Could do min and max etc as well. \n    mfccs = np.mean(librosa.feature.mfcc(y=X, \n                                        sr=sample_rate, \n                                        n_mfcc=13),\n                    axis=0)\n    features=mfccs\n    df.loc[counter] = [features]\n    counter=counter+1   \n\n# Check a few records to make sure its processed successfully\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:05:05.852253Z","iopub.execute_input":"2022-05-01T20:05:05.852815Z","iopub.status.idle":"2022-05-01T20:07:08.850503Z","shell.execute_reply.started":"2022-05-01T20:05:05.852506Z","shell.execute_reply":"2022-05-01T20:07:08.849818Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"#concatinating the feature column into the complete dataframe\ndf = pd.concat([ref,pd.DataFrame(df['feature'].values.tolist())],axis=1)\ndf[:5]","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:08.851981Z","iopub.execute_input":"2022-05-01T20:07:08.852315Z","iopub.status.idle":"2022-05-01T20:07:09.218438Z","shell.execute_reply.started":"2022-05-01T20:07:08.852259Z","shell.execute_reply":"2022-05-01T20:07:09.217465Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"# replace NA with 0\ndf=df.fillna(0)\nprint(df.shape)\ndf[:5]","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:09.222762Z","iopub.execute_input":"2022-05-01T20:07:09.223005Z","iopub.status.idle":"2022-05-01T20:07:09.256568Z","shell.execute_reply.started":"2022-05-01T20:07:09.222960Z","shell.execute_reply":"2022-05-01T20:07:09.255584Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:09.258388Z","iopub.execute_input":"2022-05-01T20:07:09.258706Z","iopub.status.idle":"2022-05-01T20:07:09.263261Z","shell.execute_reply.started":"2022-05-01T20:07:09.258645Z","shell.execute_reply":"2022-05-01T20:07:09.262397Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels','source'],axis=1)\n                                                    , df.labels\n                                                    , test_size=0.25\n                                                    , shuffle=True\n                                                    , random_state=42\n                                                   )\n\n# Lets see how the data present itself before normalisation \nX_train[150:160]","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:09.265141Z","iopub.execute_input":"2022-05-01T20:07:09.265571Z","iopub.status.idle":"2022-05-01T20:07:09.308060Z","shell.execute_reply.started":"2022-05-01T20:07:09.265408Z","shell.execute_reply":"2022-05-01T20:07:09.307177Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"# Lets do data normalization\n#Here we are using z-score normalization technique\nmean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\n\nX_train = (X_train - mean)/std\nX_test = (X_test - mean)/std\n\n# Check the dataset now \nX_train[150:160]","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:09.309509Z","iopub.execute_input":"2022-05-01T20:07:09.309989Z","iopub.status.idle":"2022-05-01T20:07:09.622040Z","shell.execute_reply.started":"2022-05-01T20:07:09.309805Z","shell.execute_reply":"2022-05-01T20:07:09.621215Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"from keras.utils import np_utils, to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:09.623559Z","iopub.execute_input":"2022-05-01T20:07:09.623938Z","iopub.status.idle":"2022-05-01T20:07:09.628807Z","shell.execute_reply.started":"2022-05-01T20:07:09.623886Z","shell.execute_reply":"2022-05-01T20:07:09.627963Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\n# Label encode the target \nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\n\nprint(X_train.shape)\nprint(lb.classes_)\n#print(y_train[0:10])\n#print(y_test[0:10])\n\n# Pickel the lb object for future use \nfilename = 'labels'\noutfile = open(filename,'wb')\npickle.dump(lb,outfile)\noutfile.close()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:09.630510Z","iopub.execute_input":"2022-05-01T20:07:09.631145Z","iopub.status.idle":"2022-05-01T20:07:09.649430Z","shell.execute_reply.started":"2022-05-01T20:07:09.631087Z","shell.execute_reply":"2022-05-01T20:07:09.648471Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"X_train = np.expand_dims(X_train, axis=2)\nX_test = np.expand_dims(X_test, axis=2)\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:09.650517Z","iopub.execute_input":"2022-05-01T20:07:09.650878Z","iopub.status.idle":"2022-05-01T20:07:09.657611Z","shell.execute_reply.started":"2022-05-01T20:07:09.650696Z","shell.execute_reply":"2022-05-01T20:07:09.656853Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras import regularizers\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential, Model, model_from_json\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\nfrom keras.utils import np_utils, to_categorical\nfrom keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:09.659137Z","iopub.execute_input":"2022-05-01T20:07:09.659632Z","iopub.status.idle":"2022-05-01T20:07:09.667764Z","shell.execute_reply.started":"2022-05-01T20:07:09.659581Z","shell.execute_reply":"2022-05-01T20:07:09.667142Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1))) \n# X_train.shape[1] = No. of Columns\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(256, 8, padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling1D(pool_size=(8)))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling1D(pool_size=(8)))\nmodel.add(Conv1D(64, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(64, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Flatten())\nmodel.add(Dense(14)) # Target class number\nmodel.add(Activation('softmax'))\nopt = keras.optimizers.Adam(lr=0.0001)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:09.669453Z","iopub.execute_input":"2022-05-01T20:07:09.669945Z","iopub.status.idle":"2022-05-01T20:07:10.056604Z","shell.execute_reply.started":"2022-05-01T20:07:09.669709Z","shell.execute_reply":"2022-05-01T20:07:10.055941Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history=model.fit(X_train, y_train, batch_size=20, epochs=100, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:07:10.060523Z","iopub.execute_input":"2022-05-01T20:07:10.060822Z","iopub.status.idle":"2022-05-01T20:10:57.357450Z","shell.execute_reply.started":"2022-05-01T20:07:10.060703Z","shell.execute_reply":"2022-05-01T20:10:57.356772Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:10:57.359663Z","iopub.execute_input":"2022-05-01T20:10:57.359965Z","iopub.status.idle":"2022-05-01T20:10:57.524437Z","shell.execute_reply.started":"2022-05-01T20:10:57.359918Z","shell.execute_reply":"2022-05-01T20:10:57.523701Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"model2 = Sequential()\n\nmodel2.add(Conv1D(256, 5,padding='same',\n                 input_shape=(216,1)))\nmodel2.add(Activation('relu'))\nmodel2.add(Conv1D(128, 5,padding='same'))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.1))\nmodel2.add(MaxPooling1D(pool_size=(8)))\nmodel2.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.2))\nmodel2.add(Conv1D(128, 5,padding='same',))\nmodel2.add(Activation('relu'))\nmodel2.add(Flatten())\nmodel2.add(Dense(14))\nmodel2.add(Activation('softmax'))\nopt = keras.optimizers.Adam(lr=0.00001, decay=1e-6)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:10:57.526040Z","iopub.execute_input":"2022-05-01T20:10:57.526386Z","iopub.status.idle":"2022-05-01T20:10:57.654413Z","shell.execute_reply.started":"2022-05-01T20:10:57.526330Z","shell.execute_reply":"2022-05-01T20:10:57.653740Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:10:57.656078Z","iopub.execute_input":"2022-05-01T20:10:57.656514Z","iopub.status.idle":"2022-05-01T20:10:57.668315Z","shell.execute_reply.started":"2022-05-01T20:10:57.656332Z","shell.execute_reply":"2022-05-01T20:10:57.666666Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"model2.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history_2=model2.fit(X_train, y_train, batch_size=16, epochs=200, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:10:57.670304Z","iopub.execute_input":"2022-05-01T20:10:57.672772Z","iopub.status.idle":"2022-05-01T20:15:01.251356Z","shell.execute_reply.started":"2022-05-01T20:10:57.670658Z","shell.execute_reply":"2022-05-01T20:15:01.250691Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_history_2.history['loss'])\nplt.plot(model_history_2.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('loss2.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:15:01.252663Z","iopub.execute_input":"2022-05-01T20:15:01.252955Z","iopub.status.idle":"2022-05-01T20:15:01.467522Z","shell.execute_reply.started":"2022-05-01T20:15:01.252907Z","shell.execute_reply":"2022-05-01T20:15:01.466766Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"markdown","source":"**Observation**\n\nHere we found that Accuracy is arround 0.9901 and loss is 0.0291 \nBut When we look around Validation set we found that val_loss: 1.0878  val_acc: 0.7398\nWhich signifies the overfitting as val_loss>train_loss","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model3 = Sequential()\n\nmodel3.add(Conv1D(256, 5,padding='same',\n                 input_shape=(216,1)))\nmodel3.add(Activation('relu'))\nmodel3.add(Conv1D(128, 5,padding='same'))\nmodel3.add(Activation('relu'))\nmodel3.add(Dropout(0.1))\nmodel3.add(MaxPooling1D(pool_size=(8)))\nmodel3.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.2))\nmodel3.add(Conv1D(128, 5,padding='same',))\nmodel3.add(Activation('relu'))\nmodel3.add(Flatten())\nmodel3.add(Dense(14))\nmodel3.add(Activation('softmax'))\nopt1 = keras.optimizers.Adam(lr=0.00001, decay=1e-6)\nmodel3.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:15:01.468958Z","iopub.execute_input":"2022-05-01T20:15:01.469431Z","iopub.status.idle":"2022-05-01T20:15:01.598701Z","shell.execute_reply.started":"2022-05-01T20:15:01.469376Z","shell.execute_reply":"2022-05-01T20:15:01.597892Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"model3.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history_3=model3.fit(X_train, y_train, batch_size=16, epochs=200, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:15:01.603123Z","iopub.execute_input":"2022-05-01T20:15:01.603409Z","iopub.status.idle":"2022-05-01T20:19:05.877410Z","shell.execute_reply.started":"2022-05-01T20:15:01.603357Z","shell.execute_reply":"2022-05-01T20:19:05.876802Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_history_3.history['loss'])\nplt.plot(model_history_3.history['val_loss'])\nplt.title('model 3 loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('loss_Adam_200_epochs.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:19:05.879671Z","iopub.execute_input":"2022-05-01T20:19:05.879976Z","iopub.status.idle":"2022-05-01T20:19:06.094572Z","shell.execute_reply.started":"2022-05-01T20:19:05.879929Z","shell.execute_reply":"2022-05-01T20:19:06.093480Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"model4 = Sequential()\n\nmodel4.add(Conv1D(256, 5,padding='same',\n                 input_shape=(216,1)))\nmodel4.add(Activation('relu'))\nmodel4.add(Conv1D(128, 5,padding='same'))\nmodel4.add(Activation('relu'))\nmodel4.add(Dropout(0.1))\nmodel4.add(MaxPooling1D(pool_size=(8)))\nmodel4.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.2))\nmodel4.add(Conv1D(128, 5,padding='same',))\nmodel4.add(Activation('relu'))\nmodel4.add(Flatten())\nmodel4.add(Dense(14))\nmodel4.add(Activation('softmax'))\nopt1 = keras.optimizers.Adam(lr=0.00001, decay=1e-6)\nmodel4.summary()\n\nmodel4.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history_4=model4.fit(X_train, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test))\n\nplt.plot(model_history_4.history['loss'])\nplt.plot(model_history_4.history['val_loss'])\n# plt.title('Adam+200')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('loss_Adam_100_epochs.png')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:19:06.096064Z","iopub.execute_input":"2022-05-01T20:19:06.096521Z","iopub.status.idle":"2022-05-01T20:19:06.222328Z","shell.execute_reply.started":"2022-05-01T20:19:06.096333Z","shell.execute_reply":"2022-05-01T20:19:06.221610Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"model5 = Sequential()\nmodel5.add(Conv1D(256, 5,padding='same',\n                 input_shape=(216,1)))\nmodel5.add(Activation('relu'))\nmodel5.add(Conv1D(128, 5,padding='same'))\nmodel5.add(Activation('relu'))\nmodel5.add(Dropout(0.1))\nmodel5.add(MaxPooling1D(pool_size=(8)))\nmodel5.add(Activation('relu'))\nmodel5.add(Conv1D(128, 5,padding='same',))\nmodel5.add(Activation('relu'))\nmodel5.add(Conv1D(128, 5,padding='same',))\nmodel5.add(Activation('relu'))\nmodel5.add(Dropout(0.2))\nmodel5.add(Conv1D(128, 5,padding='same',))\nmodel5.add(Activation('relu'))\nmodel5.add(Flatten())\nmodel5.add(Dense(14))\nmodel5.add(Activation('softmax'))\nopt1 = keras.optimizers.Adam(lr=0.00001, decay=1e-6)\nmodel5.summary()\nmodel5.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history_5=model5.fit(X_train, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test))\nplt.plot(model_history_5.history['loss'])\nplt.plot(model_history_5.history['val_loss'])\n# plt.title('Adam+200')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('full_loss_Adam_100_epochs.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:28:06.178177Z","iopub.execute_input":"2022-05-01T20:28:06.178470Z","iopub.status.idle":"2022-05-01T20:30:32.246578Z","shell.execute_reply.started":"2022-05-01T20:28:06.178418Z","shell.execute_reply":"2022-05-01T20:30:32.245771Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"model6 = Sequential()\nmodel6.add(Conv1D(256, 5,padding='same',\n                 input_shape=(216,1)))\nmodel6.add(Activation('relu'))\nmodel6.add(Conv1D(128, 5,padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(Activation('relu'))\nmodel6.add(Dropout(0.2))\nmodel6.add(Activation('relu'))\nmodel6.add(MaxPooling1D(pool_size=(8)))\nmodel6.add(Activation('relu'))\nmodel6.add(Dropout(0.2))\nmodel6.add(Conv1D(128, 5,padding='same',))\nmodel6.add(BatchNormalization())\nmodel6.add(Activation('relu'))\nmodel6.add(Dropout(0.2))\nmodel6.add(Conv1D(128, 5,padding='same',))\nmodel6.add(BatchNormalization())\nmodel6.add(Activation('relu'))\nmodel6.add(Dropout(0.2))\nmodel6.add(Conv1D(128, 5,padding='same',))\nmodel6.add(BatchNormalization())\nmodel6.add(Activation('relu'))\nmodel6.add(Flatten())\nmodel6.add(Dense(14))\nmodel6.add(Activation('softmax'))\nopt1 = keras.optimizers.Adam(lr=0.00001, decay=1e-6)\nmodel6.summary()\nmodel6.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history_6=model6.fit(X_train, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test))\nplt.plot(model_history_6.history['loss'])\nplt.plot(model_history_6.history['val_loss'])\n# plt.title('Adam+200')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('full_loss_Adam_100_epochs.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T20:39:59.137224Z","iopub.execute_input":"2022-05-01T20:39:59.137521Z","iopub.status.idle":"2022-05-01T20:44:09.856991Z","shell.execute_reply.started":"2022-05-01T20:39:59.137472Z","shell.execute_reply":"2022-05-01T20:44:09.856105Z"},"trusted":true},"execution_count":150,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}