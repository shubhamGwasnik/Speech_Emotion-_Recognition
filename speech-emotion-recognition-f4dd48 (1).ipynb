{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries \nimport librosa\nimport librosa.display\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom matplotlib.pyplot import specgram\nimport pandas as pd\nimport glob \nfrom sklearn.metrics import confusion_matrix\nimport IPython.display as ipd  # To play sound in the notebook\nimport os\nimport sys\nimport warnings\n# ignore warnings \nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-01T21:08:52.991573Z","iopub.execute_input":"2022-05-01T21:08:52.991887Z","iopub.status.idle":"2022-05-01T21:08:52.998773Z","shell.execute_reply.started":"2022-05-01T21:08:52.991837Z","shell.execute_reply":"2022-05-01T21:08:52.998004Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\nTESS = \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\nRAV = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:53.177913Z","iopub.execute_input":"2022-05-01T21:08:53.178213Z","iopub.status.idle":"2022-05-01T21:08:53.185736Z","shell.execute_reply.started":"2022-05-01T21:08:53.178159Z","shell.execute_reply":"2022-05-01T21:08:53.184798Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"dir_list = os.listdir(RAV)\ndir_list.sort()\n\nemotion = []\ngender = []\npath = []\nfor i in dir_list:\n    fname = os.listdir(RAV + i)\n    for f in fname:\n        part = f.split('.')[0].split('-')\n        emotion.append(int(part[2]))\n        temp = int(part[6])\n        if temp%2 == 0:\n            temp = \"female\"\n        else:\n            temp = \"male\"\n        gender.append(temp)\n        path.append(RAV + i + '/' + f)\n\n        \nRAV_df = pd.DataFrame(emotion)\nRAV_df = RAV_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\nRAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\nRAV_df.columns = ['gender','emotion']\nRAV_df['labels'] =RAV_df.gender + '_' + RAV_df.emotion\nRAV_df['source'] = 'RAVDESS'  \nRAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)\nRAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\nRAV_df.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:53.290312Z","iopub.execute_input":"2022-05-01T21:08:53.290606Z","iopub.status.idle":"2022-05-01T21:08:53.349352Z","shell.execute_reply.started":"2022-05-01T21:08:53.290552Z","shell.execute_reply":"2022-05-01T21:08:53.348701Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"# Pick a fearful track\nfname = RAV + 'Actor_14/03-01-06-02-02-02-14.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:53.434167Z","iopub.execute_input":"2022-05-01T21:08:53.434435Z","iopub.status.idle":"2022-05-01T21:08:53.775968Z","shell.execute_reply.started":"2022-05-01T21:08:53.434387Z","shell.execute_reply":"2022-05-01T21:08:53.774995Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"# Pick a happy track\nfname = RAV + 'Actor_14/03-01-03-02-02-02-14.wav'  \ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:53.777964Z","iopub.execute_input":"2022-05-01T21:08:53.778385Z","iopub.status.idle":"2022-05-01T21:08:54.144737Z","shell.execute_reply.started":"2022-05-01T21:08:53.778223Z","shell.execute_reply":"2022-05-01T21:08:54.143817Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"dir_list = os.listdir(TESS)\ndir_list.sort()\ndir_list","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:54.146656Z","iopub.execute_input":"2022-05-01T21:08:54.147157Z","iopub.status.idle":"2022-05-01T21:08:54.158005Z","shell.execute_reply.started":"2022-05-01T21:08:54.146961Z","shell.execute_reply":"2022-05-01T21:08:54.157003Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"path = []\nemotion = []\n\nfor i in dir_list:\n    fname = os.listdir(TESS + i)\n    for f in fname:\n        if i == 'OAF_angry' or i == 'YAF_angry':\n            emotion.append('female_angry')\n        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n            emotion.append('female_disgust')\n        elif i == 'OAF_Fear' or i == 'YAF_fear':\n            emotion.append('female_fear')\n        elif i == 'OAF_happy' or i == 'YAF_happy':\n            emotion.append('female_happy')\n        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n            emotion.append('female_neutral')                                \n        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n            emotion.append('female_surprise')               \n        elif i == 'OAF_Sad' or i == 'YAF_sad':\n            emotion.append('female_sad')\n        else:\n            emotion.append('Unknown')\n        path.append(TESS + i + \"/\" + f)\n\nTESS_df = pd.DataFrame(emotion, columns = ['labels'])\nTESS_df['source'] = 'TESS'\nTESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\nTESS_df.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:54.159883Z","iopub.execute_input":"2022-05-01T21:08:54.160421Z","iopub.status.idle":"2022-05-01T21:08:54.200426Z","shell.execute_reply.started":"2022-05-01T21:08:54.160363Z","shell.execute_reply":"2022-05-01T21:08:54.199599Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"code","source":"# lets play a fearful track \nfname = TESS + 'YAF_fear/YAF_dog_fear.wav' \n\ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:54.202800Z","iopub.execute_input":"2022-05-01T21:08:54.203116Z","iopub.status.idle":"2022-05-01T21:08:54.760024Z","shell.execute_reply.started":"2022-05-01T21:08:54.203056Z","shell.execute_reply":"2022-05-01T21:08:54.759110Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"# lets play a happy track \nfname =  TESS + 'YAF_happy/YAF_dog_happy.wav' \n\ndata, sampling_rate = librosa.load(fname)\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(data, sr=sampling_rate)\n\n# Lets play the audio \nipd.Audio(fname)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:54.761938Z","iopub.execute_input":"2022-05-01T21:08:54.762414Z","iopub.status.idle":"2022-05-01T21:08:55.385710Z","shell.execute_reply.started":"2022-05-01T21:08:54.762192Z","shell.execute_reply":"2022-05-01T21:08:55.384496Z"},"trusted":true},"execution_count":164,"outputs":[]},{"cell_type":"code","source":"EmotionData = pd.concat([ RAV_df, TESS_df], axis = 0)\nprint(EmotionData.labels.value_counts())\n#EmotionData.head()\nEmotionData.to_csv(\"Data_path.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:55.388201Z","iopub.execute_input":"2022-05-01T21:08:55.388857Z","iopub.status.idle":"2022-05-01T21:08:55.448263Z","shell.execute_reply.started":"2022-05-01T21:08:55.388518Z","shell.execute_reply":"2022-05-01T21:08:55.447336Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"EmotionData.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:55.449735Z","iopub.execute_input":"2022-05-01T21:08:55.450236Z","iopub.status.idle":"2022-05-01T21:08:55.464677Z","shell.execute_reply.started":"2022-05-01T21:08:55.450178Z","shell.execute_reply":"2022-05-01T21:08:55.463646Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"# lets pick up the meta-data that we got from our first part of the Kernel\nref = pd.read_csv(\"Data_path.csv\")\nref.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:55.466550Z","iopub.execute_input":"2022-05-01T21:08:55.467103Z","iopub.status.idle":"2022-05-01T21:08:55.495750Z","shell.execute_reply.started":"2022-05-01T21:08:55.466976Z","shell.execute_reply":"2022-05-01T21:08:55.494786Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"markdown","source":"**FEATURE EXTRACTION**\nThere are lots of features which we can get from an audio data such as \n* Spectral Centroid\n* Zero Crossing Rate\n* Chroma Frequencies\n* Mel Frequency Ceptral Coefficient(MFCC)\n* Spectral Roll off\nBut for human voice characterization and modelling MFCC is the best feature so that's why we are using MFCC feature and extract it for each of the data.","metadata":{}},{"cell_type":"markdown","source":"Lets extract MFCC feature for one of the example voice","metadata":{}},{"cell_type":"code","source":"# Source - RAVDESS; Gender - Male; Emotion - Happy \npath = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/Actor_11/03-01-03-01-02-02-11.wav\"\nX, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)  \nmfcc = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13)\n\n# audio wave\nplt.figure(figsize=(20, 15))\nplt.subplot(3,1,1)\nlibrosa.display.waveplot(X, sr=sample_rate)\nplt.title('Audio sampled at 44100 hrz')\n\n# MFCC\nplt.figure(figsize=(20, 15))\nplt.subplot(3,1,1)\n#Here we are displaying Spectrogram for the Happy voice and lets visualiza how its look like\nlibrosa.display.specshow(mfcc, x_axis='time')\nplt.ylabel('MFCC')\nplt.colorbar()\nplt.savefig(\"audio_signal.png\")\n\nipd.Audio(path)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:55.497494Z","iopub.execute_input":"2022-05-01T21:08:55.498043Z","iopub.status.idle":"2022-05-01T21:08:56.271092Z","shell.execute_reply.started":"2022-05-01T21:08:55.497832Z","shell.execute_reply":"2022-05-01T21:08:56.269852Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"markdown","source":"Now lets extract this feature for entire dataset and then concatinate this feature column into our dataframe","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(columns=['feature'])\n\n# loop feature extraction over the entire dataset\ncounter=0\nfor index,path in enumerate(ref.path):\n    X, sample_rate = librosa.load(path\n                                  , res_type='kaiser_fast'\n                                  ,duration=2.5\n                                  ,sr=44100\n                                  ,offset=0.5\n                                 )\n    sample_rate = np.array(sample_rate)\n    \n    # mean as the feature. Could do min and max etc as well. \n    mfccs = np.mean(librosa.feature.mfcc(y=X, \n                                        sr=sample_rate, \n                                        n_mfcc=13),\n                    axis=0)\n    features=mfccs\n    df.loc[counter] = [features]\n    counter=counter+1   \n\n# Check a few records to make sure its processed successfully\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:08:56.275469Z","iopub.execute_input":"2022-05-01T21:08:56.275996Z","iopub.status.idle":"2022-05-01T21:11:02.499088Z","shell.execute_reply.started":"2022-05-01T21:08:56.275785Z","shell.execute_reply":"2022-05-01T21:11:02.498280Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"code","source":"#concatinating the feature column into the complete dataframe\ndf = pd.concat([ref,pd.DataFrame(df['feature'].values.tolist())],axis=1)\ndf[:5]","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:02.500768Z","iopub.execute_input":"2022-05-01T21:11:02.501026Z","iopub.status.idle":"2022-05-01T21:11:02.840129Z","shell.execute_reply.started":"2022-05-01T21:11:02.500982Z","shell.execute_reply":"2022-05-01T21:11:02.839398Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"code","source":"# replace NA with 0\ndf=df.fillna(0)\nprint(df.shape)\ndf[:5]","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:02.841435Z","iopub.execute_input":"2022-05-01T21:11:02.841868Z","iopub.status.idle":"2022-05-01T21:11:02.880594Z","shell.execute_reply.started":"2022-05-01T21:11:02.841820Z","shell.execute_reply":"2022-05-01T21:11:02.879666Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:02.881855Z","iopub.execute_input":"2022-05-01T21:11:02.882117Z","iopub.status.idle":"2022-05-01T21:11:02.886348Z","shell.execute_reply.started":"2022-05-01T21:11:02.882073Z","shell.execute_reply":"2022-05-01T21:11:02.885322Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels','source'],axis=1)\n                                                    , df.labels\n                                                    , test_size=0.25\n                                                    , shuffle=True\n                                                    , random_state=42\n                                                   )\n\n# Lets see how the data present itself before normalisation \nX_train[150:160]","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:02.887692Z","iopub.execute_input":"2022-05-01T21:11:02.888184Z","iopub.status.idle":"2022-05-01T21:11:02.930592Z","shell.execute_reply.started":"2022-05-01T21:11:02.888124Z","shell.execute_reply":"2022-05-01T21:11:02.929846Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"# Lets do data normalization\n#Here we are using z-score normalization technique\nmean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\n\nX_train = (X_train - mean)/std\nX_test = (X_test - mean)/std\n\n# Check the dataset now \nX_train[150:160]","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:02.932027Z","iopub.execute_input":"2022-05-01T21:11:02.932561Z","iopub.status.idle":"2022-05-01T21:11:03.549282Z","shell.execute_reply.started":"2022-05-01T21:11:02.932511Z","shell.execute_reply":"2022-05-01T21:11:03.548637Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"from keras.utils import np_utils, to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:03.551776Z","iopub.execute_input":"2022-05-01T21:11:03.552308Z","iopub.status.idle":"2022-05-01T21:11:03.557108Z","shell.execute_reply.started":"2022-05-01T21:11:03.552258Z","shell.execute_reply":"2022-05-01T21:11:03.556427Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\n# Label encode the target \nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\n\nprint(X_train.shape)\nprint(lb.classes_)\n#print(y_train[0:10])\n#print(y_test[0:10])\n\n# Pickel the lb object for future use \nfilename = 'labels'\noutfile = open(filename,'wb')\npickle.dump(lb,outfile)\noutfile.close()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:03.558848Z","iopub.execute_input":"2022-05-01T21:11:03.559323Z","iopub.status.idle":"2022-05-01T21:11:03.575808Z","shell.execute_reply.started":"2022-05-01T21:11:03.559130Z","shell.execute_reply":"2022-05-01T21:11:03.574856Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"X_train = np.expand_dims(X_train, axis=2)\nX_test = np.expand_dims(X_test, axis=2)\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:03.577291Z","iopub.execute_input":"2022-05-01T21:11:03.577849Z","iopub.status.idle":"2022-05-01T21:11:03.585135Z","shell.execute_reply.started":"2022-05-01T21:11:03.577796Z","shell.execute_reply":"2022-05-01T21:11:03.584172Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras import regularizers\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential, Model, model_from_json\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\nfrom keras.utils import np_utils, to_categorical\nfrom keras.callbacks import ModelCheckpoint","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:03.586956Z","iopub.execute_input":"2022-05-01T21:11:03.587748Z","iopub.status.idle":"2022-05-01T21:11:03.595830Z","shell.execute_reply.started":"2022-05-01T21:11:03.587634Z","shell.execute_reply":"2022-05-01T21:11:03.595044Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1))) \n# X_train.shape[1] = No. of Columns\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(256, 8, padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling1D(pool_size=(8)))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling1D(pool_size=(8)))\nmodel.add(Conv1D(64, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(64, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Flatten())\nmodel.add(Dense(14)) # Target class number\nmodel.add(Activation('softmax'))\nopt = keras.optimizers.Adam(lr=0.0001)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:03.598402Z","iopub.execute_input":"2022-05-01T21:11:03.599128Z","iopub.status.idle":"2022-05-01T21:11:03.996845Z","shell.execute_reply.started":"2022-05-01T21:11:03.599074Z","shell.execute_reply":"2022-05-01T21:11:03.996081Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history=model.fit(X_train, y_train, batch_size=20, epochs=100, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:11:03.998664Z","iopub.execute_input":"2022-05-01T21:11:03.999012Z","iopub.status.idle":"2022-05-01T21:14:59.848463Z","shell.execute_reply.started":"2022-05-01T21:11:03.998952Z","shell.execute_reply":"2022-05-01T21:14:59.847792Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:14:59.850663Z","iopub.execute_input":"2022-05-01T21:14:59.851123Z","iopub.status.idle":"2022-05-01T21:15:00.001540Z","shell.execute_reply.started":"2022-05-01T21:14:59.851072Z","shell.execute_reply":"2022-05-01T21:15:00.000733Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"model2 = Sequential()\n\nmodel2.add(Conv1D(256, 5,padding='same',\n                 input_shape=(216,1)))\nmodel2.add(Activation('relu'))\nmodel2.add(Conv1D(128, 5,padding='same'))\nmodel2.add(Activation('relu'))\nmodel2.add(Dropout(0.1))\nmodel2.add(MaxPooling1D(pool_size=(8)))\nmodel2.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.2))\nmodel2.add(Conv1D(128, 5,padding='same',))\nmodel2.add(Activation('relu'))\nmodel2.add(Flatten())\nmodel2.add(Dense(14))\nmodel2.add(Activation('softmax'))\nopt = keras.optimizers.Adam(lr=0.00001, decay=1e-6)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:15:00.002842Z","iopub.execute_input":"2022-05-01T21:15:00.003196Z","iopub.status.idle":"2022-05-01T21:15:00.130157Z","shell.execute_reply.started":"2022-05-01T21:15:00.003071Z","shell.execute_reply":"2022-05-01T21:15:00.129379Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"model2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:15:00.131923Z","iopub.execute_input":"2022-05-01T21:15:00.132456Z","iopub.status.idle":"2022-05-01T21:15:00.144907Z","shell.execute_reply.started":"2022-05-01T21:15:00.132329Z","shell.execute_reply":"2022-05-01T21:15:00.144001Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"code","source":"model2.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history_2=model2.fit(X_train, y_train, batch_size=16, epochs=200, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:15:00.148405Z","iopub.execute_input":"2022-05-01T21:15:00.148762Z","iopub.status.idle":"2022-05-01T21:19:19.357506Z","shell.execute_reply.started":"2022-05-01T21:15:00.148692Z","shell.execute_reply":"2022-05-01T21:19:19.356754Z"},"trusted":true},"execution_count":184,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_history_2.history['loss'])\nplt.plot(model_history_2.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('loss2.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:19:19.361221Z","iopub.execute_input":"2022-05-01T21:19:19.361510Z","iopub.status.idle":"2022-05-01T21:19:19.764216Z","shell.execute_reply.started":"2022-05-01T21:19:19.361460Z","shell.execute_reply":"2022-05-01T21:19:19.763137Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"markdown","source":"**Observation**\n\nHere we found that Accuracy is arround 0.9901 and loss is 0.0291 \nBut When we look around Validation set we found that val_loss: 1.0878  val_acc: 0.7398\nWhich signifies the overfitting as val_loss>train_loss","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model3 = Sequential()\n\nmodel3.add(Conv1D(256, 5,padding='same',\n                 input_shape=(216,1)))\nmodel3.add(Activation('relu'))\nmodel3.add(Conv1D(128, 5,padding='same'))\nmodel3.add(Activation('relu'))\nmodel3.add(Dropout(0.1))\nmodel3.add(MaxPooling1D(pool_size=(8)))\nmodel3.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.2))\nmodel3.add(Conv1D(128, 5,padding='same',))\nmodel3.add(Activation('relu'))\nmodel3.add(Flatten())\nmodel3.add(Dense(14))\nmodel3.add(Activation('softmax'))\nopt1 = keras.optimizers.Adam(lr=0.00001, decay=1e-6)\nmodel3.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:19:19.766229Z","iopub.execute_input":"2022-05-01T21:19:19.766795Z","iopub.status.idle":"2022-05-01T21:19:19.952654Z","shell.execute_reply.started":"2022-05-01T21:19:19.766733Z","shell.execute_reply":"2022-05-01T21:19:19.951818Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"model3.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history_3=model3.fit(X_train, y_train, batch_size=16, epochs=200, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:19:19.954075Z","iopub.execute_input":"2022-05-01T21:19:19.954559Z","iopub.status.idle":"2022-05-01T21:23:41.297318Z","shell.execute_reply.started":"2022-05-01T21:19:19.954505Z","shell.execute_reply":"2022-05-01T21:23:41.296677Z"},"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_history_3.history['loss'])\nplt.plot(model_history_3.history['val_loss'])\nplt.title('model 3 loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('loss_Adam_200_epochs.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:23:41.298677Z","iopub.execute_input":"2022-05-01T21:23:41.298971Z","iopub.status.idle":"2022-05-01T21:23:41.506516Z","shell.execute_reply.started":"2022-05-01T21:23:41.298924Z","shell.execute_reply":"2022-05-01T21:23:41.505802Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"model4 = Sequential()\n\nmodel4.add(Conv1D(256, 5,padding='same',\n                 input_shape=(216,1)))\nmodel4.add(Activation('relu'))\nmodel4.add(Conv1D(128, 5,padding='same'))\nmodel4.add(Activation('relu'))\nmodel4.add(Dropout(0.1))\nmodel4.add(MaxPooling1D(pool_size=(8)))\nmodel4.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Conv1D(128, 5,padding='same',))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.2))\nmodel4.add(Conv1D(128, 5,padding='same',))\nmodel4.add(Activation('relu'))\nmodel4.add(Flatten())\nmodel4.add(Dense(14))\nmodel4.add(Activation('softmax'))\nopt1 = keras.optimizers.Adam(lr=0.00001, decay=1e-6)\nmodel4.summary()\n\nmodel4.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history_4=model4.fit(X_train, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test))\n\nplt.plot(model_history_4.history['loss'])\nplt.plot(model_history_4.history['val_loss'])\n# plt.title('Adam+200')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('loss_Adam_100_epochs.png')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:23:41.507921Z","iopub.execute_input":"2022-05-01T21:23:41.508422Z","iopub.status.idle":"2022-05-01T21:25:54.862025Z","shell.execute_reply.started":"2022-05-01T21:23:41.508354Z","shell.execute_reply":"2022-05-01T21:25:54.861311Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"model5 = Sequential()\nmodel5.add(Conv1D(256, 5,padding='same',\n                 input_shape=(216,1)))\nmodel5.add(Activation('relu'))\nmodel5.add(Conv1D(128, 5,padding='same'))\nmodel5.add(Activation('relu'))\nmodel5.add(Dropout(0.1))\nmodel5.add(MaxPooling1D(pool_size=(8)))\nmodel5.add(Activation('relu'))\nmodel5.add(Conv1D(128, 5,padding='same',))\nmodel5.add(Activation('relu'))\nmodel5.add(Conv1D(128, 5,padding='same',))\nmodel5.add(Activation('relu'))\nmodel5.add(Dropout(0.2))\nmodel5.add(Conv1D(128, 5,padding='same',))\nmodel5.add(Activation('relu'))\nmodel5.add(Flatten())\nmodel5.add(Dense(14))\nmodel5.add(Activation('softmax'))\nopt1 = keras.optimizers.Adam(lr=0.00001, decay=1e-6)\nmodel5.summary()\nmodel5.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history_5=model5.fit(X_train, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test))\nplt.plot(model_history_5.history['loss'])\nplt.plot(model_history_5.history['val_loss'])\n# plt.title('Adam+200')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('full_loss_Adam_100_epochs.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:25:54.863561Z","iopub.execute_input":"2022-05-01T21:25:54.863870Z","iopub.status.idle":"2022-05-01T21:28:30.645703Z","shell.execute_reply.started":"2022-05-01T21:25:54.863820Z","shell.execute_reply":"2022-05-01T21:28:30.645088Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"model6 = Sequential()\nmodel6.add(Conv1D(256, 5,padding='same',\n                 input_shape=(216,1)))\nmodel6.add(Activation('relu'))\nmodel6.add(Conv1D(128, 5,padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(Activation('relu'))\nmodel6.add(Dropout(0.2))\nmodel6.add(Activation('relu'))\nmodel6.add(MaxPooling1D(pool_size=(8)))\nmodel6.add(Activation('relu'))\nmodel6.add(Dropout(0.2))\nmodel6.add(Conv1D(128, 5,padding='same',))\nmodel6.add(BatchNormalization())\nmodel6.add(Activation('relu'))\nmodel6.add(Dropout(0.2))\nmodel6.add(Conv1D(128, 5,padding='same',))\nmodel6.add(BatchNormalization())\nmodel6.add(Activation('relu'))\nmodel6.add(Dropout(0.2))\nmodel6.add(Conv1D(128, 5,padding='same',))\nmodel6.add(BatchNormalization())\nmodel6.add(Activation('relu'))\nmodel6.add(Flatten())\nmodel6.add(Dense(14))\nmodel6.add(Activation('softmax'))\nopt1 = keras.optimizers.Adam(lr=0.00001, decay=1e-6)\nmodel6.summary()\nmodel6.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel_history_6=model6.fit(X_train, y_train, batch_size=16, epochs=100, validation_data=(X_test, y_test))\nplt.plot(model_history_6.history['loss'])\nplt.plot(model_history_6.history['val_loss'])\n# plt.title('Adam+200')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('full_loss_Adam_100_epochs.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T21:28:30.648695Z","iopub.execute_input":"2022-05-01T21:28:30.648933Z","iopub.status.idle":"2022-05-01T21:32:48.917427Z","shell.execute_reply.started":"2022-05-01T21:28:30.648889Z","shell.execute_reply":"2022-05-01T21:32:48.916759Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}